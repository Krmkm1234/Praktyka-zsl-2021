{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport tensorflow as tf\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Import Warnings\nimport warnings\n\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n# from sklearn.cross_validation import train_test_split\n# Import tensorflow as the backend for Keras\n\nfrom keras import backend as K\n\nK.set_image_data_format('channels_first')\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\n# from keras.optimizers import SGD,RMSprop,adam\nfrom keras.callbacks import TensorBoard\n# Import required libraries for cnfusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n\nPATH = os.getcwd()\n# Define data path\ndata_path = '../input/images-dataset/data/data'\ndata_dir_list = os.listdir(data_path)\ndata_dir_list\n\nimg_rows = 128\nimg_cols = 128\nnum_channel = 1\nnum_epoch = 100\n# Define the number of classes\nnum_classes = 7\nimg_data_list = []\nfor dataset in data_dir_list:\n    img_list = os.listdir(data_path + '/' + dataset)\n    print('Loaded the images of dataset-' + '{}\\n'.format(dataset))\n    for img in img_list:\n        input_img = cv2.imread(data_path + '/' + dataset + '/' + img)\n        input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n        input_img_resize = cv2.resize(input_img, (128, 128))\n        img_data_list.append(input_img_resize)\n\nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data /= 255\nprint(img_data.shape)\n\nif num_channel == 1:\n    if K.image_data_format() == 'channels_first':\n        img_data = np.expand_dims(img_data, axis=1)\n        print(img_data.shape)\n    else:\n        img_data = np.expand_dims(img_data, axis=4)\n        print(img_data.shape)\n\nelse:\n    if K.image_data_format() == 'channels_first':\n        img_data = np.rollaxis(img_data, 3, 1)\n        print(img_data.shape)\n\nnum_classes = 7\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,), dtype='int64')\nlabels[0:365] = 0\nlabels[365:567] = 1\nlabels[567:987] = 2\nlabels[987:1189] = 3\nlabels[1189:1399] = 4\nlabels[1399:1601] = 5\nlabels[1601:1803] = 6\nnames = ['bike', 'cars', 'cats', 'dogs', 'flowers', 'horses', 'human']\n\nY = np_utils.to_categorical(labels, num_classes)\n\nx, y = shuffle(img_data, Y, random_state=2)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n\nprint(\"X_train shape = {}\".format(X_train.shape))\nprint(\"X_test shape = {}\".format(X_test.shape))\n\nimage = X_train[1203, :].reshape((128, 128))\nplt.imshow(image)\nplt.show()\n\n# Initialising the input shape\ninput_shape = img_data[0].shape\n# Design the CNN Sequential model\ncnn_model = Sequential([\n    Convolution2D(32, 3, 3, padding='same', activation='relu', input_shape=input_shape),\n    Convolution2D(32, 3, 3, activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.5),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\ncnn_model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[\"accuracy\"])\n\ncnn_model.summary()\n\nhist = cnn_model.fit(X_train, y_train, batch_size=16, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_accuracy = hist.history['val_accuracy']\nxc = range(num_epoch)\n\nplt.figure(1, figsize=(10, 5))\nplt.plot(xc, train_loss)\nplt.plot(xc, val_loss)\nplt.xlabel('Number of Epochs')\nplt.ylabel('Loss')\nplt.title('Train Loss vs Validation Loss')\nplt.grid(True)\nplt.legend(['Train Loss', 'Validation Loss'])\nplt.style.use(['classic'])\n\nplt.figure(2, figsize=(10, 5))\nplt.plot(xc, train_acc)\nplt.plot(xc, val_accuracy)\nplt.xlabel('Number of Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy vs Validation Accuracy')\nplt.grid(True)\nplt.legend(['Train Accuracy', 'Validation Accuracy'], loc=4)\nplt.style.use(['classic'])\n\nscore = cnn_model.evaluate(X_test, y_test, verbose=0)\nprint('Test Loss:', score[0])\nprint('Test Accuracy:', score[1])\n\ntest_image = X_test[0:1]\nprint(test_image.shape)\nprint(cnn_model.predict(test_image))\n# print(cnn_model.predict_classes(test_image))\npredict_x = cnn_model.predict(test_image)\nclasses_x = np.argmax(predict_x, axis=1)\nprint(y_test[0:1])\n\nimage = test_image.reshape((128, 128))\nplt.imshow(image)\nplt.show()\n\ntest_img = cv2.imread('../input/images-dataset/data/human/rider-104.jpg')\ntest_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\ntest_img = cv2.resize(test_img, (128, 128))\ntest_img = np.array(test_img)\ntest_img = test_img.astype('float32')\ntest_img /= 255\nprint(test_img.shape)\n\nif num_channel == 1:\n    if K.image_data_format() == 'channels_first':\n        test_img = np.expand_dims(test_img, axis=0)\n        test_img = np.expand_dims(test_img, axis=0)\n        print(test_img.shape)\n    else:\n        test_img = np.expand_dims(test_img, axis=3)\n        test_img = np.expand_dims(test_img, axis=0)\n        print(test_img.shape)\n\nelse:\n    if K.image_data_format() == 'channels_first':\n        test_img = np.rollaxis(test_img, 2, 0)\n        test_img = np.expand_dims(test_img, axis=0)\n        print(test_img.shape)\n    else:\n        test_img = np.expand_dims(test_img, axis=0)\n        print(test_img.shape)\n\n# Predicting the test image\nprint((cnn_model.predict(test_img)))\nprint(np.argmax(cnn_model.predict(test_img), axis=-1))\n\n\ndef get_featuremaps(cnn_model, layer_idx, X_batch):\n    get_activations = K.function([cnn_model.layers[0].input, K.learning_phase()],\n                                 [cnn_model.layers[layer_idx].output, ])\n    activations = get_activations([X_batch, 0])\n    return activations\n\n\ntf.compat.v1.disable_eager_execution()\nlayer_num = 3\nfilter_num = 0\nactivations = get_featuremaps(cnn_model, int(layer_num), test_img)\nprint(np.shape(activations))\n\nfeature_maps = activations[0][0]\nprint(np.shape(feature_maps))\n\nif K.image_data_format() == 'channels_first':\n    feature_maps = np.rollaxis((np.rollaxis(feature_maps, 2, 0)), 2, 0)\nprint(feature_maps.shape)\n\nfig = plt.figure(figsize=(16, 16))\nplt.imshow(feature_maps[:, :, filter_num], cmap='gray')\nplt.savefig(\"featuremaps-layer-{}\".format(layer_num) + \"-filternum-{}\".format(filter_num) + '.jpg')\nnum_of_featuremaps = feature_maps.shape[2]\nfig = plt.figure(figsize=(16, 16))\nplt.title(\"featuremaps-layer-{}\".format(layer_num))\nsubplot_num = int(np.ceil(np.sqrt(num_of_featuremaps)))\nfor i in range(int(num_of_featuremaps)):\n    ax = fig.add_subplot(subplot_num, subplot_num, i + 1)\n    # ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n    ax.imshow(feature_maps[:, :, i], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()\nplt.show()\n\n# Print the confusion matrix\nY_pred = cnn_model.predict(X_test)\nprint(Y_pred)\ny_pred = np.argmax(Y_pred, axis=1)\nprint(y_pred)\ntarget_names = ['Class 0 (flowers)', 'Class 1 (cars)', 'Class 2 (cats)', 'Class 3 (horses)',\n                'Class 4 (human)', 'Class 5 (bike)', 'Class 6 (dogs)']\nprint(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n\nprint('Confusion Matrix \\n')\nprint(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float32') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Confusion matrix with Normalization\")\n    else:\n        print('Confusion matrix without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\n# Compute confusion matrix\ncnf_matrix = (confusion_matrix(np.argmax(y_test, axis=1), y_pred))\nnp.set_printoptions(precision=2)\nplt.figure()\n\nplot_confusion_matrix(cnf_matrix, classes=target_names,\n                      title='Confusion Matrix without Normalisation')\nplt.show()\n\nplot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n                      title='Normalized Confusion Matrix')\nplt.figure()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-18T08:09:16.670811Z","iopub.execute_input":"2021-11-18T08:09:16.671149Z","iopub.status.idle":"2021-11-18T08:12:17.143577Z","shell.execute_reply.started":"2021-11-18T08:09:16.671112Z","shell.execute_reply":"2021-11-18T08:12:17.142923Z"},"trusted":true},"execution_count":2,"outputs":[]}]}